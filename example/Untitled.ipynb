{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "sys.path.append(\"R:/JoePriceResearch/record_linking/projects/deep_learning/ml-record-linking/Splycer\")\n",
    "from record_set import RecordDataFrame\n",
    "from compare_set import CompareCSR\n",
    "from feature_engineer import FeatureEngineer\n",
    "from xgboost_match import XGBoostMatch\n",
    "os.chdir(\"R:/JoePriceResearch/record_linking/projects/deep_learning/ml-record-linking/example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in the census data.\n",
    "delaware_1910 = RecordDataFrame(2, pd.read_csv(\"delaware_1910.csv\", index_col=\"index\"))\n",
    "delaware_1920 = RecordDataFrame(3, pd.read_csv(\"delaware_1920.csv\", index_col=\"index\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in the compares set\n",
    "compares = pd.read_csv(\"delaware_compares.csv\")\n",
    "compares = CompareCSR([1,2], compares.index_1910.values, compares.index_1920.values, np.ones(compares.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct the feature engineer\n",
    "years = [1,2]\n",
    "feature_engineer = FeatureEngineer()\n",
    "features = [\"imputer\", \"bool match\", \"euclidean distance\", \"jaro-winkler\", \n",
    "            \"ngram\", \"drop\", \"commonality weight\"] #FIXME add immigration imputer to FeatureEngineer\n",
    "first_vec = [f\"first_vec{i}\" for i in range(2, 202)]\n",
    "last_vec = [f\"last_vec{i}\" for i in range(2,202)]\n",
    "cols_to_drop = [\"marstat\", \"birth_year\", \"household\", \"immigration\", \"race\", \"rel\", \"female\",\n",
    "                \"bp\", \"mbp\", \"fbp\", \"state\", \"county\", \"cohort1\", \n",
    "                \"cohort2\", \"last_sdxn\", \"first_sdxn\", \"last_init\",\n",
    "                \"first_init\", \"bp_comm\", \"first_comm\", \"last_comm\", \"bp_lat\", \"bp_lon\",\n",
    "                \"res_lat\", \"res_lon\", \"full_name\"]\n",
    "cols_to_drop.extend(first_vec)\n",
    "cols_to_drop.extend(last_vec)\n",
    "feature_params = [{\"cols\": [\"first_comm\", \"last_comm\"], \"years\": years}, \n",
    "                  {\"vars_to_match\": [\"marstat\", \"race\", \"rel\", \"mbp\", \"fbp\", \"first_sdxn\", \"last_sdxn\", \"bp\", \"county\"], \"years\": years},\n",
    "                  {\"variables\": [[\"immigration\"], [\"birth_year\"], [\"res_lat\", \"res_lon\"], [\"bp_lat\", \"bp_lon\"], [f\"first_vec{i}\" for i in range(2, 202)], [f\"last_vec{i}\" for i in range(2,202)]], \"new_cols\": [\"immigration_dist\", \"birth_year_dist\", \"geodist\", \"bp_geodist\", \"first_vec_dist\", \"last_vec_dist\"], \"years\": years},\n",
    "                  {\"string_col\": [\"first\", \"last\"], \"dist_metric\": \"jw\", \"years\": years},\n",
    "                  {\"string_col\": [\"first\", \"last\"], \"n\": 2, \"years\": years},\n",
    "                  {\"cols_to_drop\": [\"first\", \"last\"], \"both_years\": True, \"years\": years},\n",
    "                  {\"cols\": [\"first_jw\", \"last_jw\", \"first_sdxn_match\", \"last_sdxn_match\", \"bp_match\"], \"comm_cols\": [\"first\", \"last\", \"first\", \"last\", \"bp\"], \"years\": years}]\n",
    "\n",
    "for i, j in zip(features, feature_params):\n",
    "    feature_engineer.add_feature(i, j) #this adds features to your feature object. when you run feature_engineer.create_features(), it computes all of the features above.\n",
    "feature_engineer.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x81 in position 36: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-625363ba0465>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Construct XGBoostMatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"R:/JoePriceResearch/record_linking/projects/deep_learning/ml-record-linking/model.xgboost\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpkl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mxbg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXGBoostMatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelaware_1910\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelaware_1920\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompares\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_engineer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mR:\\JoePriceResearch\\Python\\AnacondaNew\\envs\\ml_rec_env\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x81 in position 36: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "#Construct XGBoostMatch\n",
    "with open(\"R:/JoePriceResearch/record_linking/projects/deep_learning/ml-record-linking/model.xgboost\", \"r\") as file:\n",
    "    model = pkl.load(file)\n",
    "xbg = XGBoostMatch(delaware_1910, delaware_1920, compares, feature_engineer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
